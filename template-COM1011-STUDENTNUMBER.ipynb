{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ab2525c2",
      "metadata": {
        "id": "ab2525c2"
      },
      "source": [
        "# COURSEWORK SPECIFICATION\n",
        "\n",
        "## COM1011 - Fundamentals of Machine Learning\n",
        "\n",
        "**Module Leader:** Chico Camargo\n",
        "\n",
        "**Academic Year:** 2025/26\n",
        "\n",
        "**Title:** Coursework 2\n",
        "\n",
        "**Submission deadline:** 1st December at 12:00pm (noon), 2025.\n",
        "\n",
        "This assessment contributes **70%** of the total module mark and assesses the following intended learning outcomes:\n",
        "\n",
        "1. Understanding and identifying the compromises and trade-offs that must be made when using a machine learning approach;\n",
        "2. Analysing problems from a data-centric point of view, choosing among a range of supervised and unsupervised machine learning techniques and using relevant software libraries to solve them\n",
        "3. Stating the importance and difficulty of establishing machine learning solutions;\n",
        "4. Using elementary python for implementing machine learning algorithms.\n",
        "5. Identifying the compromises that must be made when translating theory into practice\n",
        "\n",
        "\n",
        "__________________________\n",
        "\n",
        "# What to submit\n",
        "\n",
        "You are required to submit your assignment **1st December at 12:00pm (noon), 2025**.\n",
        "\n",
        "Please do all your work in this Jupyter notebook. Make a separate cell for every few lines of code, and use separate cells for text, like this one.\n",
        "Save your file in the format `COM1011_STUDENTNUMBER.ipynb` and zip it.\n",
        "For example, if your student number is 12345678, save your coursework as `COM1011_12345678.ipynb`.\n",
        "Once you have done that, zip the file, producing a file called `COM1011_12345678.zip`. This is the file you will have to upload and submit to ELE.\n",
        "\n",
        "This assignment will also use additional CSV files. Do not include them in the `COM1011_STUDENTNUMBER.zip` file.\n",
        "\n",
        "____________________\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43008855",
      "metadata": {
        "id": "43008855"
      },
      "source": [
        "# Answer template\n",
        "\n",
        "Please use this notebook for your coursework. Feel free to add more cells for your code and answers, but try to stick to this format. This will make it easier to mark everyone's work fairly.\n",
        "\n",
        "___________________"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08803e3b",
      "metadata": {
        "id": "08803e3b"
      },
      "source": [
        "_____________________\n",
        "\n",
        "# Part A – Probability and Bayesian Inference [10 marks]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zCgXYLVWhBBN",
      "metadata": {
        "id": "zCgXYLVWhBBN"
      },
      "source": [
        "Consider a simple poker game. Suppose a deck of poker cards contains four suits: Clubs, Spades, Hearts, and Diamonds, with each suit having 8 cards numbered from 1 to 8. So the total number of cards is 32. The card with the number 8 is the largest, while the card with the number 1 is the smallest. Cards of different suits with the same number are considered equal."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7o3FnPRohMCK",
      "metadata": {
        "id": "7o3FnPRohMCK"
      },
      "source": [
        "(1) Suppose person A fetches a card with the number 3 of Clubs from the deck. Person B then fetches another card from the deck. What is the probability that person B's card is less than person A's card? Explain how you arrived at the answer. [1 mark]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pbnr-UlUh8DQ",
      "metadata": {
        "id": "pbnr-UlUh8DQ"
      },
      "source": [
        "Answer to (1): 8/31\n",
        "\n",
        "Assuming the ordering of ther cards is random, the probability of a chosen card being less than a 3 of Clubs would be 8/31 (4 pairs of cards 1 and 2 from the different suits. There's 31 cards because one was taken but not put back)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WmhVpBCnlwVM",
      "metadata": {
        "id": "WmhVpBCnlwVM"
      },
      "source": [
        "(2) If you have drawn four cards sequentially from the deck of 32 cards. What is the total probability that the four cards have the same number 3? (1 mark)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OyX3NyuRojYu",
      "metadata": {
        "id": "OyX3NyuRojYu"
      },
      "source": [
        "Answer to (2): 1/35960\n",
        "\n",
        "Probability equals the number of desired cards divided by total number of cards. Since there are only 4 cards of identical number and they arent returned, the probability of drawing 4 cards of identical number are:\n",
        "\n",
        "4/32 * 3/31 * 2/30 * 1/29 = 24/863040 = 1/35960"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "z_tgx8geurMD",
      "metadata": {
        "id": "z_tgx8geurMD"
      },
      "source": [
        "\n",
        "\n",
        "(3) If you have drawn four cards sequentially from the deck of 32 cards. What is the total probability that the four cards are of Clubs? Explain how you arrived at the answer [1 mark]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BZ6q7AFEvBmQ",
      "metadata": {
        "id": "BZ6q7AFEvBmQ"
      },
      "source": [
        "Answer to (3): 7/3596\n",
        "\n",
        "Since there are 8 cards of identical number and they arent returned, the probability of drawing 4 cards of identical suit are:\n",
        "\n",
        "8/32 * 7/31 * 6/30 * 5/29 = 7/3596"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IsqQsUNEo2nq",
      "metadata": {
        "id": "IsqQsUNEo2nq"
      },
      "source": [
        "(4) Suppose person A fetches a card with the number 3 of Hearts from the deck. Person B then fetches another card with the number 6 from the deck. What is the probability that person B's card is also of Hearts? Explain how you arrived at the answer by using Bayesian formula. [2 mark]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZTX_TYwfrvmd",
      "metadata": {
        "id": "ZTX_TYwfrvmd"
      },
      "source": [
        "Answer to (4): 1/4\n",
        "\n",
        "Bayes' Theorem:\n",
        "\n",
        "    P(A|B) = P(B|A)*P(A) / P(B)\n",
        "\n",
        "There are 31 cards left in the deck, 7 of which are hearts. If B drew a 6, there is a 1/4 chance it is also of hearts.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "D2WhCmwHsYt3",
      "metadata": {
        "id": "D2WhCmwHsYt3"
      },
      "source": [
        "(5) Suppose person A fetches a card with the number 2 from the deck of 32 cards. Person B then fetches another card with the number 4 from the deck. What is the probability that person B's card and A's card have the same suit? Explain how you arrived at the answer by using Bayesian formula. [2 marks]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CI1Mj6KktVkO",
      "metadata": {
        "id": "CI1Mj6KktVkO"
      },
      "source": [
        "Answer to (5): 7/124\n",
        "\n",
        "Cards = 32 then 31\n",
        "\n",
        "Hearts = 8 then 7\n",
        "\n",
        "Bayes' Theorem:\n",
        "\n",
        "    P(A|B) = P(B|A)*P(A) / P(B)\n",
        "\n",
        "A then B = \n",
        "\n",
        "    8/32 * 7/31 = 56/992 = 7/124"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gEHQS3rsLzjw",
      "metadata": {
        "id": "gEHQS3rsLzjw"
      },
      "source": [
        "(6) Briefly explain how  Naive Bayesian classifier works such as how the conditional probability is computed for both the cases of discrete features and contineous features. [2 marks]\n",
        "\n",
        "What is the major limitation of Naive Bayesian classifier in practice? [1 mark]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UQtXpc05MAmS",
      "metadata": {
        "id": "UQtXpc05MAmS"
      },
      "source": [
        "Answer to (6):\n",
        "\n",
        "The Naive Bayesian Classifier is a machine learning model that uses probability to predict future data points. BEcause it's Naive, it carries many assumptions and limitations, such as assuming that all variables are independent of eachother, which limits how accurate the model's predictions will be when it comes to generalising.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NvN1Mj7Pegyb",
      "metadata": {
        "id": "NvN1Mj7Pegyb"
      },
      "source": [
        "_____________________\n",
        "\n",
        "# Part B – Clustering and Dimension Reduction [32 marks]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06caede4",
      "metadata": {
        "id": "06caede4"
      },
      "source": [
        "## 1 Implement K-means clustering for fashion-MNIST dataset:\n",
        "\n",
        "(7) Load the fashion-MNIST test dataset (`t10k-labels-idx1-ubyte.gz` and `t10k-images-idx3-ubyte.gz`), then obtain the image data denoted as `X_test` and the ground truth labels denoted as `y_test`. After that, pre-process `X_test` by scaling the image pixel values to values between 0 and 1. Source code is provided. [0 mark]\n",
        "\n",
        "[hint: check https://github.com/zalandoresearch/fashion-mnist?tab=readme-ov-file#get-the-data for detailed information about fashion-MNIST dataset]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "f56fa082",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f56fa082",
        "outputId": "8795586d-28a2-40d5-8d18-c63c86207397"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.0\n",
            "(60000, 784)\n",
            "(60000,)\n",
            "(10000, 784)\n",
            "(10000,)\n"
          ]
        }
      ],
      "source": [
        "# answer to (7). You may need to change path for `t10k-labels-idx1-ubyte.gz` and `t10k-images-idx3-ubyte.gz`\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "def load_mnist(path, kind='train'):\n",
        "    import os\n",
        "    import gzip\n",
        "    import numpy as np\n",
        "\n",
        "    \"\"\"Load fashion-MNIST data from `path`\"\"\"\n",
        "    labels_path = os.path.join(path,\n",
        "                               '%s-labels-idx1-ubyte.gz'\n",
        "                               % kind)\n",
        "    images_path = os.path.join(path,\n",
        "                               '%s-images-idx3-ubyte.gz'\n",
        "                               % kind)\n",
        "\n",
        "    with gzip.open(labels_path, 'rb') as lbpath:\n",
        "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
        "                               offset=8)\n",
        "\n",
        "    with gzip.open(images_path, 'rb') as imgpath:\n",
        "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
        "                               offset=16).reshape(len(labels), 784)\n",
        "\n",
        "    return images, labels\n",
        "\n",
        "location = r\"\"\n",
        "X_test, y_test = load_mnist(location, kind='t10k')\n",
        "\n",
        "X_test = X_test/255\n",
        "\n",
        "X_train, y_train = load_mnist(location)\n",
        "\n",
        "X_train = X_train/255\n",
        "\n",
        "print(np.max(X_test))\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HKC2u6Z6X6Av",
      "metadata": {
        "id": "HKC2u6Z6X6Av"
      },
      "source": [
        "(8) Obtain all the test images and their (ground-truth) labels for '3','6','7', respectively, and then rearrange the samples and labels in a random order. [1 mark]\n",
        "\n",
        "[hint: check https://numpy.org/doc/2.2/reference/generated/numpy.isin.html and https://numpy.org/doc/2.1/reference/random/generated/numpy.random.permutation.html]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "uuzNcw_XY91s",
      "metadata": {
        "id": "uuzNcw_XY91s"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[3 7 7 ... 6 7 3]\n",
            "[6 6 7 ... 3 7 6]\n"
          ]
        }
      ],
      "source": [
        "train_mask = np.isin(y_train, [3, 6, 7])\n",
        "X_train = X_train[train_mask]\n",
        "y_train = y_train[train_mask]\n",
        "\n",
        "test_mask = np.isin(y_test, [3, 6, 7])\n",
        "X_test = X_test[test_mask]\n",
        "y_test = y_test[test_mask]\n",
        "\n",
        "print(y_train)\n",
        "print(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20c8773f",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "8QrkkwD6Zbc5",
      "metadata": {
        "id": "8QrkkwD6Zbc5"
      },
      "source": [
        "(9) Use PCA with 2 components to visualise the test data samples in (8) with different colors representing different real (i.e., ground-truth) clusters in a 2d plot. In the plot legend, indicate which colours correspond to which digits. You should use three colors for the three labels: '3','6', '7'. [2 marks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xzBlJ07TZtMt",
      "metadata": {
        "id": "xzBlJ07TZtMt"
      },
      "outputs": [],
      "source": [
        "#Answer to (9)\n",
        "#perform PCA with 2 components and further visualize the data samples in a 2d plot\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vJJmX9e3ZVbd",
      "metadata": {
        "id": "vJJmX9e3ZVbd"
      },
      "source": [
        "(10) Using the K-means clustering algorithm to cluster the test images in (8) directly, using k=2, 3 and 4. And then use PCA with 2 components to visualize the test data samples with different colors representing different predicted clusters in a 2d plot for each k value. You need to produce three plots, one plot for each k value. [3 marks]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7dcwJWajaINV",
      "metadata": {
        "id": "7dcwJWajaINV"
      },
      "outputs": [],
      "source": [
        "#answer to (10)\n",
        "#perform K-means\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KTkBMtnBJose",
      "metadata": {
        "id": "KTkBMtnBJose"
      },
      "source": [
        "(11) Calculate and print the respective Davies-Bouldin scores for k=2,3,4 in (10). Which k value produces the best clustering, according to the Davies-Bouldin score. Then answer: is it consistent with the ground truth number of clusters from fashion-MNIST?   [2 marks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0Ub4KK6nQX7V",
      "metadata": {
        "id": "0Ub4KK6nQX7V"
      },
      "outputs": [],
      "source": [
        "#answer to (11)\n",
        "from sklearn.metrics import davies_bouldin_score\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qzwQGU55bH_C",
      "metadata": {
        "id": "qzwQGU55bH_C"
      },
      "source": [
        "continued answer to (11)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UtobRt2ek92J",
      "metadata": {
        "id": "UtobRt2ek92J"
      },
      "source": [
        " (12) Calculate and print the respective silhouette_scores for k=2,3,4 in (10). Which k value produces the best clustering, according to the Silhouette score. Then answer: is it consistent with the ground truth number of clusters from fashion-MNIST?  [2 marks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oiyu5guHegZt",
      "metadata": {
        "id": "oiyu5guHegZt"
      },
      "outputs": [],
      "source": [
        "#answer to (12)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Ye_FhFRGhFx6",
      "metadata": {
        "id": "Ye_FhFRGhFx6"
      },
      "source": [
        "Continued answer to (12)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BSnuCxljcbtb",
      "metadata": {
        "id": "BSnuCxljcbtb"
      },
      "source": [
        "(13) Using the K-means clustering algorithm to cluster the first two components of PCA being applied to the tested images, using k=2, 3 and 4. And then compare the clustering results with those from (10) by making of 2 subplots for each value of k: one subplot with the clustering done on the whole images, one sublplot with the clustering done with just the two first components of the PCA. [2 marks]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3QwAmsjFlS5s",
      "metadata": {
        "id": "3QwAmsjFlS5s"
      },
      "outputs": [],
      "source": [
        "#answer to (13)\n",
        "#perform K-means\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fjj7_P7Wpz0",
      "metadata": {
        "id": "3fjj7_P7Wpz0"
      },
      "source": [
        "(14) Compute the Silhouette scores for different k values in (13) and then compare with those obtained in (12). Answer: are the Silhouette scores obtained from the clustering of whole images consistent with the Silhouette scores obtained by clustering only the two first PCA components?  \n",
        "[2 marks]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dTw5uRxurDy-",
      "metadata": {
        "id": "dTw5uRxurDy-"
      },
      "outputs": [],
      "source": [
        "#answer to (14)\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vt41IpDgZA2C",
      "metadata": {
        "id": "vt41IpDgZA2C"
      },
      "source": [
        "Continued answer to (14)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6RxbRG_RYpmZ",
      "metadata": {
        "id": "6RxbRG_RYpmZ"
      },
      "source": [
        "(15) Let's compare the result of dimensionality reductions by PCA with 2 components and tSNE with 2 components. Apply PCA and tSNE to the test images of '3', '6', and '7', and then visualize the results in 2 subplots, one for each method. Use different colors to represent different real (ground truth) clusters.  [2 marks]  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "k6_z7K6jY3bY",
      "metadata": {
        "id": "k6_z7K6jY3bY"
      },
      "outputs": [],
      "source": [
        "#answer to (15)\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "whuTmPPyZT98",
      "metadata": {
        "id": "whuTmPPyZT98"
      },
      "source": [
        "## 2. Implementing DBSCAN clustering for classes of '3', '6', and '7' of fashion-MNIST dataset:\n",
        "\n",
        "\n",
        "(16) Firstly, use the DBSCAN clustering algorithm to cluster the test images directly by setting the eps parameter to 0.3 and the min_sample to 5. And then apply DBSCAN to cluster the first 2 PCA components of the test images by setting the eps parameter to 0.3 and the min_sample to 5.\n",
        "Visualize the clustering results in two subplots for each k value and also print out the numbers of estimated clusters. [2 marks]\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Xj3PIFxCaUW0",
      "metadata": {
        "id": "Xj3PIFxCaUW0"
      },
      "outputs": [],
      "source": [
        "#Answer for (16)\n",
        "\n",
        "from sklearn.cluster import DBSCAN\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "q77yC0FEvXtU",
      "metadata": {
        "id": "q77yC0FEvXtU"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "(17) Changing the eps parameter in (16) to 0.5 and 1, and briefly summarize your observations of the experimental results in terms of the stability of the DBSCAN method in comparison to K-means: is DBSCAN more or less stable than K-means, when it comes to changing hyperparameters? [2 marks]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WfwMwQ3a1LPq",
      "metadata": {
        "id": "WfwMwQ3a1LPq"
      },
      "source": [
        "Answer to (17)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5BAfzOH2u_OF",
      "metadata": {
        "id": "5BAfzOH2u_OF"
      },
      "source": [
        "(18) Compare the performance of K-means and DBSCAN when clustering the data points obtained by applying tSNE with 2 components on test images of classes '3', '6', and '7'.\n",
        "\n",
        "Set k in K-means to k=3. Play with different values of (eps, min_samples) in DBSCAN to find a proper setup. Visualize the clustering results in 2 subplots. Answer: which method is more robust from the above results? How did you arrive at that conclusion? [2 marks]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PzJRNweAwD74",
      "metadata": {
        "id": "PzJRNweAwD74"
      },
      "outputs": [],
      "source": [
        "#Answer to (18)\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GxKowif7ypQG",
      "metadata": {
        "id": "GxKowif7ypQG"
      },
      "source": [
        "Continued answer to (18).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lRVCF5_RzCEg",
      "metadata": {
        "id": "lRVCF5_RzCEg"
      },
      "source": [
        "(19) Implement bisecting K-means algorithm and Gausian mixture models to cluster the 2 components of tSNE for the test images of classes '3', '6', and '7'. Set the number of clusters to be 3.    [2 marks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21359540",
      "metadata": {
        "id": "21359540"
      },
      "outputs": [],
      "source": [
        "# Answer to (19)\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.cluster import BisectingKMeans\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Cqosv-rE5Kdy",
      "metadata": {
        "id": "Cqosv-rE5Kdy"
      },
      "source": [
        "(20). Usually, DBSCAN takes longer than K-means to run, and the time it takes to run is affected by the eps parameter. Explain why that is the case. [4 marks]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VwtbsLfx5Wsl",
      "metadata": {
        "id": "VwtbsLfx5Wsl"
      },
      "source": [
        "Answer to (20)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lXAVlTRi5Qa9",
      "metadata": {
        "id": "lXAVlTRi5Qa9"
      },
      "source": [
        "(21). Provide an example of one case in which it might be better to use DBSCAN rather than K-means, and an example of one case in which it might be better to use K-means rather than DBSCAN. Explain why, in both cases. [4 marks]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "E3Dw0Kos5rNh",
      "metadata": {
        "id": "E3Dw0Kos5rNh"
      },
      "source": [
        "Answer to (21):\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "C0JJtSYDQidS",
      "metadata": {
        "id": "C0JJtSYDQidS"
      },
      "source": [
        "_____________________\n",
        "\n",
        "# Part C – Classification and Regression [32 marks]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QQJcFcff2fr1",
      "metadata": {
        "id": "QQJcFcff2fr1"
      },
      "source": [
        "## 1 Implement a multi-class Logistic Regression classifier for fashion-MNIST dataset.  [20 marks]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Ru30O7n63dlN",
      "metadata": {
        "id": "Ru30O7n63dlN"
      },
      "source": [
        "(22) Load \"train-labels-idx1-ubyte.gz\" and \"train-images-idx3-ubyte.gz\". In the variable X_tmp (see the code below), every row represents a greyscale image, and every one of the 784 columns represent a pixel value. 784 = 28 x 28. So each image is size 28*28.\n",
        "\n",
        "First, load the two files \"train-labels-idx1-ubyte.gz\" and \"train-images-idx3-ubyte.gz\". Then, perform train-test-split to prepare both the training data in terms of (X_train, y_train) and test data in terms of (X_test, y_test). The code for this question is provided below to faciliate the implementation for the following questions. [0 mark]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qQ-c7JLxSX-F",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "qQ-c7JLxSX-F",
        "outputId": "9b287623-0958-43ca-8f50-293fd6b71d05"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABJ4AAADcCAYAAAAxzGueAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAJKhJREFUeJzt3XmMX9dZP/7jZVbPeOzxbsd4guPUDYkTmoCSkoQmpRSEwpKmFIVFCBWhgtoqYKlI/INUoSKCBFRFSC1SaagEEuqCkpCWKgoSkltMKCix0mDsxMZb7PEyMx7Pvnz/4Ff9mrbP83Hu+Nhjz+v179v33nM/c8895/PkozzL5ufn5wsAAAAAXGHLr/UAAAAAALgxKTwBAAAAUIXCEwAAAABVKDwBAAAAUIXCEwAAAABVKDwBAAAAUIXCEwAAAABVKDwBAAAAUIXCEwAAAABVrLzcf7hs2bKa44Dr3vz8/LUeQmqxzeFsPNfis9y9e3eYfepTnwqzf/iHfwiz//zP/wyzqampdDzT09Nhdvvtt4fZL/zCL4TZ4cOHw+zJJ59MxzM0NJTmN4LFPIcX2/y9FjZu3Bhmv/7rvx5mTz31VJi98cYbCxnSFXfXXXeFWfaO+sIXvpCeN3uf3CgW8/wtZWnM4YGBgTR/17veFWY/93M/F2bnzp0Ls89//vNh9s1vfjPMsvlUSinve9/7wuzd7353mI2NjYVZNtZPf/rT6XiWgsU8h5fC/KWUrVu3htnJkyev4kiuP5czf/3iCQAAAIAqFJ4AAAAAqELhCQAAAIAqFJ4AAAAAqELhCQAAAIAqls1fZgsB/zd/yC3mbhyl1JvDV7s7Xdb16Zd+6ZfSY7MuNbOzs2G2atWqMOvq6gqzdevWpeOp4eDBg2E2NzcXZm9729vS854+fTrMvvrVr4bZn/7pn4bZgQMH0mtebYt5Di+FNbinpyfNs/n90Y9+NMyyDpJnz55tdFyrrpS9vb1h1tHREWY33XRTmP3jP/5jmH39619Px5N137xRLOb5W8r1NYd/+qd/OsyeeOKJMBsfH0/P297eHmYTExNhls2nrMvrpk2bwuzIkSNhVkopMzMzYXbq1KkwGx4eDrNs7m/bti0dz/PPPx9mH/nIR9JjrxeLeQ5fT/O3qewZK6WUtWvXhlnWefI3f/M3w6zVPGwq6073wgsvhFm2pz969GiY/dRP/VQ6nkuXLqX5jUBXOwAAAACuGYUnAAAAAKpQeAIAAACgCoUnAAAAAKpQeAIAAACgCoUnAAAAAKpYNn+ZvSuXQhtJWIjF3Aa2lMU3h1evXh1mTz31VJjt2bMnzJYvz2vpFy9eDLOslfP09HSYzc7OhllbW1uY9fX1hVkpeevVubm5MKv1HHZ2doZZ1n42a5/9r//6r2H2q7/6q5c3sCtoMc/hxTZ/r4X3v//9YZa1cf+DP/iDMMtaLmet2LO26KWUcuHChTAbHR0Ns6997Wth9nd/93dh1tPTk47ny1/+cprfCBbz/C1l8c3hnTt3htkf/uEfhtnp06fDrLu7O71mtkZn69rMzEyYbd++Pb1mk+u1yoeHh8MsG2u2lzh//nw6nm3btoXZ0NBQmO3duzc972KymOfwYpu/NfzLv/xLmmfvjGxNzPaI2b78C1/4Qpj9yq/8SpiVUsqKFSvCLNvvZ3Mp22fceeed6XiWgsuZv37xBAAAAEAVCk8AAAAAVKHwBAAAAEAVCk8AAAAAVKHwBAAAAEAVCk8AAAAAVKHwBAAAAEAVK6/1AJa6ZcuWhdn8/Hzj8/b29obZ/fffH2bPPfdco+tl91FKKStWrAizmZmZRtdsqtVYMwv5m/BmX/ziF8Nsx44dYXbmzJkwm5ubS6+5cmX8ysuew+yZyc6ZHXf27NkwKyWfM5nly+v894Tx8fEwm5iYCLNszjz44INhtnv37jB79dVXw4wbV3t7e5gNDQ2F2ac+9akw+8hHPhJmk5OTYdbR0RFmrcbzH//xH2H22c9+NsxuvvnmMBscHEzHA9/t937v98Ks6fPUav3p7OwMs2wNzrLXX389zIaHhxuNpZR8P9Fq/kdmZ2fDLNtLlFLK0aNHw+z2228Ps5/5mZ8Js2effTa9JkvLuXPn0jxbg7Jj+/v7w2zz5s1h9uEPfzjM7rzzzjArpZQ9e/aE2YULF8Ism4etPh9a84snAAAAAKpQeAIAAACgCoUnAAAAAKpQeAIAAACgCoUnAAAAAKpQeAIAAACgirx3J9VlrWeztqu33HJLet4PfvCDYZa1Rb906VKYZS3T9+/fn44na4WbydrRZ59ddlzTsZTSvMX9UnX33XeH2Y4dO8Ls7NmzYZa1Om3198naJ2/bti3Muru7wyx7Dqenp8OsVevkbP5nz3dbW1uYZc/+xYsX0/EcP3680Xkz2T1m77C9e/c2uh7Xt9HR0TBbv359mGVtyH/3d383zG666aYw27BhQ5iVkrd4z1oyZ/eRvTOydwJ8P3/zN38TZk888USYDQ4Ohtnp06fTa/b29oZZtl5mpqamwiybT62MjIyEWbaPbiq7j1JK6evrC7Njx46F2bPPPtt4TCwtr732Wprfe++9YZbtAycnJ8Os6dp15MiRNH/ggQfC7MSJE2HW1dUVZtl3AS6PXzwBAAAAUIXCEwAAAABVKDwBAAAAUIXCEwAAAABVKDwBAAAAUIXCEwAAAABV5P28qS5r/561Gn/44YfT8/7ET/xEmGVt0Ts6OsIsayP5nve8Jx3PX//1X4dZ1n53fn4+zLLPJ9PT05Pmc3NzYTY2NtbomkvVQw89FGbZs5Zl2d8nm0+l5C1dP/axj4XZyZMnwyybT1u3bg2zU6dOhVkppSxfHv93gaztcvbZZc/+O97xjnQ8H/7wh8Ps7NmzYZa1gM/+lo899liY7d27N8y4cWXtmjNNW6pnz/Ubb7yRHputl9u2bQuzbF3L1sMsg+9n//79Yfb1r389zH72Z382zP7t3/4tvWa2HmRz5ty5c2GWrYfZHJ6YmAizVuPJ7mNkZCTMNmzYkF6z6Xh+//d/v/F54dteeeWVNG+1x45cunQpzLL5u2fPnkbXK6WU8fHxMFu2bFmYNZ3bXB6/eAIAAACgCoUnAAAAAKpQeAIAAACgCoUnAAAAAKpQeAIAAACgCoUnAAAAAKqIewZyVWRtJDM/8iM/kuYDAwNhlrXDzFq4f/WrXw2zH/7hH07H8yd/8idh9uKLL4bZyy+/HGbf+ta3wuxHf/RHw6zVZ7dv374wy1oM870ee+yxMMtao2fPaNZuvLOzMx3P8PBwmH3mM58Js5/8yZ8Ms3e84x1h9tnPfjbMfuu3fivMSinlwIEDYdbf3x9m2Wd3+vTpMPuzP/uzdDy//du/HWZZ+9nsbzI2NhZmu3fvDrNbb701zEop5eDBg2nO9Slbn+bn58Mse2dk82XNmjWXNa4rKWvznN1jNgfhrfrkJz8ZZh/96EfD7H//93/T8w4ODoZZ1nI9WysuXryYXjPSqjV8Np5svrW1tYVZNta+vr50PM8991yYafPOlXDixIk0n56eDrNsfc7mxKlTp8Lsm9/8Zpi1mvfZvWRzP1uDs+8QXB6/eAIAAACgCoUnAAAAAKpQeAIAAACgCoUnAAAAAKpQeAIAAACgCoUnAAAAAKrQf/cqaNoe+T3veU+Y3XPPPek1szaTq1atCrOsTXmW/fu//3s6nkOHDoVZT09PmN13331h9uijj4ZZ1vKz1Vg/+MEPhtnk5GR6LG925513htmxY8fCLGvL2tHR0Xg8q1evbnTcV77ylTDLWi7fdtttYbZ37970ml/60pfC7JFHHgmzrM1z1pr27rvvTsczMzMTZtk7JWtlPzc3F2ZZW+7svVBKKQcPHkxzrk/ZWpG9FyYmJsIsa6ucPZ+tWrFn634me/dlWWdnZ6PrsXRla0X2vr///vvD7I/+6I8aj2dsbKzReLq6usJsfHw8zLL7b5Vne8FsnmZaHff00083Oi9crpMnT6Z59t0qW/OytTRbn1955ZUwa2trC7NS8vk0PDwcZtleoum6zv/PL54AAAAAqELhCQAAAIAqFJ4AAAAAqELhCQAAAIAqFJ4AAAAAqELhCQAAAIAq8l6ivMnVbqP48Y9/PMy2bNnS+Lzd3d1hlrWsnZqaCrOsvW4ppdxzzz1hlrXZzNq/Hzp0KMyy+/id3/mdMCullB/8wR8Ms8ceeyw9dim6/fbbw2xwcDDMsr9R1qo8m4dZW+VSSjl37lyaR7J7zNoqZ/O0Vdvp7D6btrS977770mtmsja727ZtC7PZ2dkwy+Z+1gb7gQceCLNSSvnc5z6X5lyfsvbm2XOfZVnL5abnXMh5s/dids7snQnfT/asZU6dOhVmhw8fTo+9+eabwyxrq37x4sUwa9qqPZtPpZQyOjoaZhs2bAizpnP46NGj6XigtrNnz6b5wMBAmL366qthls3DbD3M1vxWsu+s2TWzPWu29+by+MUTAAAAAFUoPAEAAABQhcITAAAAAFUoPAEAAABQhcITAAAAAFUoPAEAAABQhcITAAAAAFWsvNYDuJ7Mz89f1etduHAhzLZs2ZIeOz4+HmYdHR1htnJl/Ej09PSE2cTERDqerq6uMJubmwuzBx54IMze+c53htny5XFNdePGjWFWSilf+cpX0pw3+9jHPhZm2d99dHQ0zGZnZxuds9VzODMzE2b33HNPmK1bty7M+vv7w6ytrS3MNm3aFGallDI9PR1m2X22t7eH2Zo1a8LsAx/4QDqetWvXhln2vunr62t0XHYf2d+KG1f2Xh8bGwuzFStWNDrnsmXLwix7R7XSdC8xOTnZ+JpwNWTzqZRSent7wyzbC2b71pGRkTDL1pFW+4Wpqak0j2T7jMyZM2caHQdXyhtvvNH42GzuZ3vhVu+MSKt1NLtmtr/Ovgdn38u5PH7xBAAAAEAVCk8AAAAAVKHwBAAAAEAVCk8AAAAAVKHwBAAAAEAVCk8AAAAAVBH3DOSa6+7uDrNW7Sebtp0eHh4Os3PnzoXZwMBAOp6s7WXWsjq7j+zzyVpdZy17Syll+/btac6b7du3L8w2b94cZrfcckuYrV69OsxWrVoVZv/zP/8TZqXkz8U3vvGNMMuemSzLrpe1eC8lb+natM17Np8uXryYjufgwYNhls3Fpq3sT548GWZf/vKXw4wbV9O2y9kzmM3fps/uQmTzfnJyMsw2btxYYzgsUdnznc2Z48ePp+fds2dPo2tmz362v8xaqmdrZSmldHZ2htn4+HiYTUxMhNn69evD7MSJE+l4Mtl7Y2ZmpvF54Ttl8zCTzdGmx7X6LpfN7yzL9tcjIyPpNWnNL54AAAAAqELhCQAAAIAqFJ4AAAAAqELhCQAAAIAqFJ4AAAAAqELhCQAAAIAq4v6bfI+sxWLWBjZr29jT0xNmW7duDbNWLS2zvKOjI8ympqbCbGxsLMzWrFmTjufcuXNhlrVib29vD7Os/XtfX1+YvfTSS2FWSv43ueeee9Jjl6K/+qu/apStXbs2zHbt2hVmH/rQh8Lsx3/8x8OslFLOnz8fZgcOHAizoaGhMMvaNWft2Gtp+p7KWkCX0nxO/fIv/3J6Xvi27J1QSj6fsuc+a8mczYlasjbQWVv0bI6uWrUqvWbWGr7V3IfLdeTIkTTP5lu238veDdk1Z2ZmwmzdunVhVkopFy5caHTebP+d3X92TlgMsrWrqWx9ztb1LGul6X7h0qVLja/J//GLJwAAAACqUHgCAAAAoAqFJwAAAACqUHgCAAAAoAqFJwAAAACqUHgCAAAAoIq4by/fI2uxmLV5np2dDbMPfOADYbZ58+YwGxwcDLNSSunq6gqzrB1m1pJ5+/btYTY1NZWOp6OjI8ymp6fDLGstnd1j1ib3L//yL8OslFLuuuuuRuPhrclaFe/fvz/MslbFDz/8cHrNbA5nrZyzeZHN/YW0nm3aRja7ZjYPW83hrB37vn370mPhcmRzu1Weze2mFnLObI5mLdUz2btmeHg4PXZiYqLRNeGtGB8fT/Oma2J2XDYvsnWr1ViyPcr69evDrLe3Nz1vpK2trdFxcLU0Xbsy2VqZze1WsrFma3v2nX3jxo2Nx8P/8YsnAAAAAKpQeAIAAACgCoUnAAAAAKpQeAIAAACgCoUnAAAAAKpQeAIAAACgCr3h34KVK+OPq1Ur8siBAwfCLGsd3artataCsmmryKwd87lz59LxZOPN2t1mbeyzVrfHjx8Ps8cffzzMSinlySefDLNvfOMb6bG8WdYmNXsmsvmUtUEdGRlJx9N0XjRtq57df4327wuxkLa1Q0NDV/yaWavrxfbZcWW0+rsu5Bm9XmSfQUdHx1UcCUtZ9v7NzMzMpPng4GCYZet+tt/LZMe12rd3dXWF2ZkzZ8Jsw4YNYTY6OppeExazbE/b9LgsW748/n1Mq3dNdt7s+3x23oGBgfSatOYXTwAAAABUofAEAAAAQBUKTwAAAABUofAEAAAAQBUKTwAAAABUofAEAAAAQBVxP8ErpFXrxaw9ctZGMTvv9PR0mDVtEVtK69aNTfzTP/1TmF26dCnMxsfH0/O2t7eHWdauOWt1m/2tOjs70/Fkf5Omx2V/y2yse/bsSa85PDzcemBcluxZa/pMHD58OMxGRkbSY7MWqq1aK0eye8zeU61ax2eatrTN7rGtra3pcFp+7pHsHT87O9t0OFynsvd2K9l6kD1nNa5X65oLmS/ZsQvZF3Fjavq89Pb2puddu3ZtmI2NjYVZf39/et7I2bNnw6y7uzs9tq+vL8ya7heytXvHjh2NzllKne8n8N2a7j2bfp+vMZZS8r1GtpYODAw0vib/xy+eAAAAAKhC4QkAAACAKhSeAAAAAKhC4QkAAACAKhSeAAAAAKhC4QkAAACAKhSeAAAAAKhi5ZU4yYoVK8JsdnY2PXZmZuZKDOGqePDBB8Psfe97X5j92I/9WJiNjY2F2blz58Ksvb09zEopZeXK+E+b/U2y8WR/546OjnQ8nZ2dYTY/P99oPJns8xkdHU2PffTRR8Ps6aefbjQevtfy5XHdO3tGx8fHw2xqaiq9ZvacZu+ibD4tW7YszLJnOzuuVZ59dtk1Jycnw6y7u7vxeK6n9ziLV7ZOlJI/203nWvauyeZZth4uRNP3SZaVkq+JExMTrQfGkjI3N9fouMHBwTQ/cOBAmB07dizMsvUpe343bdoUZq32C0eOHGl0zb6+vjA7depUmG3dujUdD9R26623pnm2jmTvjGwPncnW4IXsoZvuZ9evX59ek9b84gkAAACAKhSeAAAAAKhC4QkAAACAKhSeAAAAAKhC4QkAAACAKhSeAAAAAKiiWX/D75K1I16I/v7+MMvaju7atavRcY8++mg6nqzNZNamPGsHOTY2Fmbr1q0Ls5MnT4ZZKXmr16wd5saNG8Msaz3bqhX7vn37wqynpyfMHnzwwTDLWncODw+H2fT0dJiVUsq9996b5lwZrdp/R7K/e6t3UdN25NkczmRjXUg79qwVbDbW7B5btc9uet5M0+O4MdVqj9z0OWs1nqttIeNp+g6Dt+KBBx5I89deey3Mjh49GmbZnnZkZCTMVq9eHWZ9fX1hVkop4+PjYZbth7ds2ZKeN7J58+Y0z/bnZ86cCbNs7rda91la3v72t6f58ePHwyz7btXW1tZoPNk+udZ6mH2f37RpU5i9853vTK+ZfQ9eSuxEAAAAAKhC4QkAAACAKhSeAAAAAKhC4QkAAACAKhSeAAAAAKhC4QkAAACAKlZeiZNk7ec//vGPp8du2LAhzNasWRNmWdv0rP3i0NBQmM3MzIRZKaVcvHgxzLLWqlnLx6xda9Z68Rd/8RfDrJRSXnzxxTDr7e0Ns6yN5MDAQHrNzB133NFoPMeOHQuzsbGxMOvq6gqznp6eMCullB07dqQ5i9e2bdvS/MKFC2GWvTeyduxZW9bF1o49G2vWCreU/F6yzw4u12J7jrJ5v5C5nR2bXTP7fFp9ditXXpHtHjeQbD2Ym5sLs+3bt4fZbbfdll7ztddeC7Nsz79+/fowO3ToUJitWrUqzG6++eYwKyX/vrB69er02CZGR0fT/PHHHw+zP//zPw+z7G8J3+nd7353mtfYC2fnbDqWVpru9w8fPhxmH/rQh9JrZt/plxK/eAIAAACgCoUnAAAAAKpQeAIAAACgCoUnAAAAAKpQeAIAAACgCoUnAAAAAKq47P66WevBT37yk2G2ZcuW9Lyzs7ONsrGxsfS8kfb29kbXK6WU8fHxRtfs6+sLsx07doTZH//xHzceS9bW8eTJk2E2MTERZs8//3yYZS1ySyll165dYbZu3bowm5qaCrO2trYwW0jb+MHBwTTnylhIK9TIzMxM42ObvhuyNrFNs1Kat3LPWidnc2ZycrLxeLLzNj0nS0+rOZHNw6bzJVsrMgt5dpu2pM60+uyyfcjIyEija3J9y9aKzHvf+94we+WVV9JjOzs7wyx7DgcGBsLsxIkTYbZ79+4wa3X/x48fD7M9e/aE2enTp8Ms2+9euHAhHc+2bdvC7JZbbgmzQ4cOpeeFb7v33nvTPPv+lNUJsvUpWw9XrrzsMsVbkq2z2Tsq+4583333LWhMS4VfPAEAAABQhcITAAAAAFUoPAEAAABQhcITAAAAAFUoPAEAAABQhcITAAAAAFVcdp/CX/u1XwuzHTt2hNnhw4fT8/b09DTK+vv70/NGsrbfWbvhUko5duxYmJ08eTLMuru7wyxru/q5z30uzH7+538+zEop5emnnw6zrC1t9pnffffdYfbQQw+l48laV05NTYVZR0dHmLW3t6fXjGQtuUvJn5Ht27c3uiZXx+TkZJpn7V5nZmYaHZe1ZM7axGbnLCWfF03bz2bHjY2NpePJrFmzpvGx8G3Zu7eUfB3J2jVnmrZ5vhaytavVWLO1FN6KPXv2hNlLL72UHpute9merunz22qdzWRre5ZlLdezPeTIyEg6nizP9vWHDh1Kzwvflj1HpZRy4cKFMMvW56ZraTZ/a63P2TWz7/ObN29Oz5u9w1p9d7mR+MUTAAAAAFUoPAEAAABQhcITAAAAAFUoPAEAAABQhcITAAAAAFUoPAEAAABQhcITAAAAAFWsvNx/eObMmTA7duxYmPX29qbnnZycbHTenp6eMGtvbw+z1atXh9n58+fDrJRSjh492mg84+PjYTYxMRFmMzMzYfalL30pzEop5eWXXw6zgYGBMOvv7w+zqampMBsaGkrHMz09HWbZfc7NzYVZW1tbo+OWLVsWZqXkz8+tt96aHsu1lf3dFyJ7Zubn5xudc/nyvO7f6jmNZONZyH1k87Srq6v1wBpck6Vl5cp8S5I9vytWrAiz6+k5y+ZZJltjS2n9voHvlO0TT506FWadnZ3peUdHR8Msm/811p9Wcy3bT3R0dDS65tjYWJht2rQpPfbEiRNhtmHDhkbjYelZu3ZtmK1fvz499vTp02GWzf0a+9LZ2dkwKyVf87JrZt8B//mf/znM3v/+96fjufvuu8Ns37596bE3EjsRAAAAAKpQeAIAAACgCoUnAAAAAKpQeAIAAACgCoUnAAAAAKpQeAIAAACgirx38XfI2nhm7Q6PHz+ennfVqlVhlrV1HBoaCrOzZ8+G2eDgYJi1auWctU9ta2sLs6zFZG9vb5hlrSCzeyyllLe//e1hdunSpTA7duxYmF24cCHMWrWWzcabtYHO2t1mx2XtdTdv3hxmpZQyPDwcZnfddVd6LNdWrZbhNdqxtxpr1u41k401u2are8zmYnd3d+uBQQtZG+NWsuc3a4te651RQ3aP2XpYijnKW/MDP/ADYZbNp1b76GyOZ3vlrHV6q2tGsrbypeRrXnbNLHv99dfDbNeuXel4slb2fX19Ydbf3x9m58+fT6/JjSf7HtNq35nNw+zYpvvS7J3Qar+Qvaey8WTz/m1ve1uYtXoPZd/L9+3blx57I7l+dlwAAAAAXFcUngAAAACoQuEJAAAAgCoUngAAAACoQuEJAAAAgCoUngAAAACo4rJ7kP7Xf/1XmH3xi18Ms9/4jd9Iz3vy5Mkwe+2118JsYmIizHp6esKsra0tzLq6usKslLx144oVK8JscnIyzLLWlFm7x7GxsTArpZRTp041Om/TlrXZ36OU/G8yNTUVZkNDQ42yrLV01iqzlFJuvvnmMMva2fLWZM9hLdk8bSq7j1ataTNNx9r0c23VVj57N9T4XFl6WrVHbtoCeSHz8GrL5mE2B7M1r5RSbrnlljDL9ncsTdk7PXtGW+1Nu7u7wyzbn2f7xKZt07N9aSn5OyXb12/bti3MXnzxxTB78MEH0/Fk+/psf7527dowO3/+fHpNbjyPPPJImJ09ezY9NltnsnmYZdk8zNbu7H1RSimdnZ1hNjIyEmbZPW7evDnMWn23vOOOO9J8qfCLJwAAAACqUHgCAAAAoAqFJwAAAACqUHgCAAAAoAqFJwAAAACqUHgCAAAAoIq4/+Zb8IlPfCLMWrXp3bt3b5gNDAyEWdbycWhoKMwuXboUZq1agmetnrNWptl5s1aRWRvYVm0kszy7j+y4hbSkzo49ffp0mGVtNvv7+8Msa92ZtcMspZSXXnopzD7/+c+H2d/+7d+m5+XNmj77mazlcil5K+emsmctm/utWq/W+HwWImvl3urdGbkW98HitXXr1sbHZi3es+es6fxdyLObjTUbT/ZOaPU+adUmG77T+vXrwyzbQw4ODqbnvf3228OsafvzbDzZvOjt7Q2zVuedmJgIsz179oTZs88+G2bZd5dW41m7dm2YZd9PWHp27twZZq3mRPb9KVvXzp8/3+icjzzySJg988wzYVZKKePj42GWfRe4ePFiet7IqlWr0vyHfuiHGp33RuMXTwAAAABUofAEAAAAQBUKTwAAAABUofAEAAAAQBUKTwAAAABUofAEAAAAQBWX3WOzafvf5557Lj1vlj/00ENh9olPfCLMduzYEWZ9fX1hlt1jKXlr5axdadaGPHPmzJkwa9XK+cSJE2E2OTkZZqOjo2HWtGV6Kfl4p6enw2xsbCzMsr/X1772tTD71re+FWallLJv37405/qVPTPZPM3amGfnbJqV0ryteiabh63Gk1nIuwG+LWtRXkopbW1tYZY929nzmc2l7J2wkGc+W/Oy82bvhJ6envSaR48ebT0w+P+sX78+zLK14ty5c+l5sz14to8+depUmLW3t4fZhQsXwuzSpUthVsrC1sRItsfOxlpKPv+ze9myZUuY/fd//3d6TW48zzzzTJi9613vanze7Pns6upqdM5svrQyMzMTZlNTU43Ome0JWu1fXn755UbXvNH4xRMAAAAAVSg8AQAAAFCFwhMAAAAAVSg8AQAAAFCFwhMAAAAAVSg8AQAAAFBF3Lv0u2RtEmt54YUXwuzee+9tdM7du3eHWdY+tpRShoaGwuymm24KsyNHjoRZ1lb58OHD6Xjgepa1P2/q5MmTaX7rrbeGWdZ6NXv/ZVnW/r3VOzXLs88ua/eatatupWm7+qbnZOnZv39/mmfzd82aNWE2Pj7eaDzLli0Ls+x9UUqdZztri57N+1JKOXjw4JUeDjewnp6eMBsbGwuztWvXNr5mZ2dnmGXtz7N1bcOGDWE2ODiYjmfVqlWNzpt9l9i5c2eYtdoTLF8e/1YgO7a3tzc9L0vLZz7zmTD79Kc/nR6brYlnz54Ns6Y1hIXUHrLx9PX1hVn2vTybS6tXr07H8xd/8RdpvlT4xRMAAAAAVSg8AQAAAFCFwhMAAAAAVSg8AQAAAFCFwhMAAAAAVSg8AQAAAFCFwhMAAAAAVay81gO42l599dUq5z1w4ECV8wKXb82aNWm+atWqMFu5Mn4drl+/PsyWL4/r91nW1tYWZgsxOzsbZitWrAizY8eOpeft7u4Os507d7Ye2PeRfT5zc3ONzsn1a2xsLM2feuqpMHvooYfCLJu/2Tshmy8zMzNh1kr23Gfz9/XXXw+zF154Ib1mq88WvtOuXbvCLHsOOzs7G18zmxfZ+jMxMRFm+/btC7PHH388HU+2J3j++efDrOmeoNX+5dKlS2G2kHcDfNsdd9yR5i+//HKj805OTjY6buPGjY2OK6WUTZs2hVlXV1eYZfO+t7c3zN773vem4zl69GiaLxV+8QQAAABAFQpPAAAAAFSh8AQAAABAFQpPAAAAAFSh8AQAAABAFQpPAAAAAFSxbH5+fv6y/uGyZbXHAte1y5xK18xim8PZeJp+lk8++WSad3R0hNnQ0FCYtbW1NRpP1jp5dHQ0PTb7DLLPLmvzPjc3F2ZTU1PpeNauXRtm+/fvD7NnnnkmPe9ispjn8GKbvzW0uscaf5/+/v4w27x5c5itXr268TXfeOONRlnWNr6VGu/bxWax38f1NIezluLZGpOteaXka9DOnTvDLGtFftNNN4XZkSNH0vGwuCzmOXw9zd9r4f777w+z2267LcwefvjhMHviiSfC7NSpU+l4su8DGzduDLO///u/D7PnnnsuveZSdznz1y+eAAAAAKhC4QkAAACAKhSeAAAAAKhC4QkAAACAKhSeAAAAAKhC4QkAAACAKpbNL+belQAAAABct/ziCQAAAIAqFJ4AAAAAqELhCQAAAIAqFJ4AAAAAqELhCQAAAIAqFJ4AAAAAqELhCQAAAIAqFJ4AAAAAqELhCQAAAIAq/h8ktBRW6gsOcgAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 1500x300 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# answer for (22). You may need to change the path for \"train-labels-idx1-ubyte.gz\" and \"train-images-idx3-ubyte.gz\".\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def load_mnist(path, kind='train'):\n",
        "    import os\n",
        "    import gzip\n",
        "    import numpy as np\n",
        "\n",
        "    \"\"\"Load fashion-MNIST data from `path`\"\"\"\n",
        "    labels_path = os.path.join(path,\n",
        "                               '%s-labels-idx1-ubyte.gz'\n",
        "                               % kind)\n",
        "    images_path = os.path.join(path,\n",
        "                               '%s-images-idx3-ubyte.gz'\n",
        "                               % kind)\n",
        "\n",
        "    with gzip.open(labels_path, 'rb') as lbpath:\n",
        "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
        "                               offset=8)\n",
        "\n",
        "    with gzip.open(images_path, 'rb') as imgpath:\n",
        "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
        "                               offset=16).reshape(len(labels), 784)\n",
        "\n",
        "    return images, labels\n",
        "\n",
        "\n",
        "X_tmp, y_tmp = load_mnist('/content/drive/MyDrive/coursework2/', kind='train')\n",
        "\n",
        "# normalization\n",
        "X_tmp = X_tmp/255.0\n",
        "\n",
        "\n",
        "plt.figure(figsize=(15,3))\n",
        "for i in range(5):\n",
        "  image = X_tmp[i,:].reshape(28,28)\n",
        "  plt.subplot(1, 5, i+1)\n",
        "  plt.imshow(image, cmap='gray')\n",
        "  plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tmp, y_tmp, test_size=0.2, random_state=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7xnajFWhwgb9",
      "metadata": {
        "id": "7xnajFWhwgb9"
      },
      "source": [
        "(23)\n",
        "\n",
        "Implement a two-class Logistic Regression classifer for classes with labels 4 and 6 in fashion-MNIST by using LogisticRegression from `sklearn.linear_model`. Set random_state to 42, solver='sag' and max_iter=200 in LogisticRegression- (look at the documentation online if needed). Print both the training and test classfication accuracices. [1 mark]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nPUWLYz5wj9o",
      "metadata": {
        "id": "nPUWLYz5wj9o"
      },
      "outputs": [],
      "source": [
        "#answer to (23)\n",
        "\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "uVFKBO8dBQNH",
      "metadata": {
        "id": "uVFKBO8dBQNH"
      },
      "source": [
        "(24) Test solver='sag', random_state=42, and max_iter={300, 500} in (23). Print both the training and test classfication accuracices. [2 marks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ae5faa4-5256-415f-aea9-54badb8344c6",
      "metadata": {
        "id": "8ae5faa4-5256-415f-aea9-54badb8344c6"
      },
      "outputs": [],
      "source": [
        "# answer to (24)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "JvvhHND5V4DH",
      "metadata": {
        "id": "JvvhHND5V4DH"
      },
      "source": [
        "(25) Plot both the training and test accuracies for the maximum iterations of 200, 300,  500 being set in LogisticRegression, based on the results from (23) and (24). Put the two curves (one for the training curve and the other for the test curve) in the same 2d plot for easy comparison. Make X axis be the number of maximum iterations (200, 300, 500) and the y axis be the accuracy. [1 mark]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2rilKsBxWgLs",
      "metadata": {
        "id": "2rilKsBxWgLs"
      },
      "outputs": [],
      "source": [
        "# Answer to (25)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VAJ9zpA9vsO1",
      "metadata": {
        "id": "VAJ9zpA9vsO1"
      },
      "source": [
        "(26) Three classification models have been obtained from (23) and (24) by setting different values for the hyper-parameter max_iter. Which model should we choose? Explain why. [1 mark]\n",
        "\n",
        "What is overfitting? Why is that a problem, and how can one avoid it? [3 marks]\n",
        "\n",
        "\n",
        "Does the plot in (25) exhibit over-fitting? Explain why. [1 mark]    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12i0E4z8wm0x",
      "metadata": {
        "id": "12i0E4z8wm0x"
      },
      "source": [
        "\n",
        "Answer to (26):"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "siEe0NlFGWuP",
      "metadata": {
        "id": "siEe0NlFGWuP"
      },
      "source": [
        "(27) Let's do some data augmentation to improve the test performance in (23) and (24). In doing so, prepare additional training data for class 4 and 6 of fashion-MNIST by flipping each image horizontally using a library like numpy.flip. Display one original image alongside its flipped version to demonstrate the augmentation.   [2 marks]\n",
        "\n",
        "Then, use both the original training data and the flipped training data to train the two-class Logistic Regression classifer. Print out the training and test accuracies for max_iter = {200, 300, 500}.  [2 marks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kt5y7Uq28HF0",
      "metadata": {
        "id": "kt5y7Uq28HF0"
      },
      "outputs": [],
      "source": [
        "# Answer to (27)\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support\n",
        "from scipy.ndimage import rotate\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7E8v9i5UEcy3",
      "metadata": {
        "id": "7E8v9i5UEcy3"
      },
      "source": [
        "(28) In general, is the image-flip technique a reasonable approach for the considered classification problem? Provide your reasoning. [2 marks]\n",
        "\n",
        "Is the test accuracy obtained in (27) better than those in (23) and (24)? [1 mark]\n",
        "\n",
        "Consider three approaches: 1-change to advanced machine learning models, 2-employ other data augmentation techniques, 3-employ other data pre-processing techniques.  What do you think is the most effective approach to improve the test performance ? Why. [2 marks]\n",
        "\n",
        "Elaborate on the most effective approach you have chosen by providing more detailed suggestions. [2 marks]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "s9om3WS-FlDb",
      "metadata": {
        "id": "s9om3WS-FlDb"
      },
      "source": [
        "Answer to (28):\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-tpsIktTzOVS",
      "metadata": {
        "id": "-tpsIktTzOVS"
      },
      "source": [
        "## 2 Implement regression for the housing dataset.  [12 marks]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QQpvJqNa2Vfp",
      "metadata": {
        "id": "QQpvJqNa2Vfp"
      },
      "source": [
        "(29) Check how normalization affects the regression performance with the dataset \"housing.csv\".\n",
        "\n",
        "Firstly, visualize the correlation matrix in terms of the heat map for all the 14 features. [0.5 mark]\n",
        "\n",
        "Secondly, implement a Linear model that use only the 'CRIM' and 'RM' to predict 'TAX' without normalization. In doing so, split the data into training and test datasets. Report both the training and test errors in terms of mean squared error (MSE). [0.5 mark]  \n",
        "\n",
        "Thirdly, do normalization (refer to the operation of scaling each feature to be in the range of [0,1]) to the data, and then implement a Linear model that use normalized 'CRIM' and normalized 'RM' to predict normalized 'TAX'. Report both the training and test errors.  What conclusions can you draw by comparing the above prediction results regarding the impact of normalization? [1 mark]  \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rgXtFGEwjxmC",
      "metadata": {
        "id": "rgXtFGEwjxmC"
      },
      "outputs": [],
      "source": [
        "# Answer to (29)\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import math\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "column_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
        "\n",
        "regression_data = pd.read_csv('/content/drive/MyDrive/coursework2/housing.csv')\n",
        "\n",
        "#regression_data=regression_data.astype(float)\n",
        "\n",
        "correlation_matrix = regression_data.corr()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xPAPBmIR64x0",
      "metadata": {
        "id": "xPAPBmIR64x0"
      },
      "source": [
        "Continued answer to (29):\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "M0OL__bRVOPb",
      "metadata": {
        "id": "M0OL__bRVOPb"
      },
      "source": [
        "(30) Check how correlation strength affects the regression performance with the dataset \"housing.csv\".\n",
        "\n",
        "Use normlized \"CRIM\" and normalized \"ZN\" to predict normalized \"TAX\" by using a linear model. Print out the training and test mean squared error. Remember using the same random_state and the same test_size when running the train_test_split function from sklearn.model_selection.   [1 mark]  \n",
        "\n",
        "Use normlized \"CRIM\" and normalized \"INDUS\" to predict normalized \"TAX\" by using a linear model. Print out the training and test mean squared error. Remember using the same random_state and the same test_size when running the train_test_split function from sklearn.model_selection.   [1 mark]  \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "roBGa849bTBw",
      "metadata": {
        "id": "roBGa849bTBw"
      },
      "outputs": [],
      "source": [
        "# Answer to (30)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OWZxXoMofTp_",
      "metadata": {
        "id": "OWZxXoMofTp_"
      },
      "source": [
        "(31) What conclusions can you draw by comparing the test errors of (29) and (30) regarding the impact of the correlation strength (check the heat map shown above)? [1 mark]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OMlrk8nygAa4",
      "metadata": {
        "id": "OMlrk8nygAa4"
      },
      "source": [
        "Answer to (31):\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3tEL9INWik0C",
      "metadata": {
        "id": "3tEL9INWik0C"
      },
      "source": [
        "(32) Convert a regression problem to a classification problem of 10 classes.\n",
        "\n",
        "First pre-processing the data for \"TAX\" to be in the range of [0,10) denoted as yy in the data type of float. Then tranform (via the rounding opertion) yy into the data type of integer within {0,1,2,.., 9} denoted as y. [1 mark]\n",
        "\n",
        "Obtain training and test datasets from  normlized \"CRIM\", normalized \"INDUS\", and the ground truth labels y. Then implement a Logistic classifer and report the training and test accuracies.  Set random_state to 42, solver='sag' and max_iter=200 in LogisticRegression. [1 mark]\n",
        "\n",
        "Rescale the prediced labels from the Logistic classifer to the range of [0, 1] and then compute and print out the mean squqred errors (MSEs) with respect to the normalized ground truth \"TAX\" for both training and test datasets.  [1 mark]\n",
        "\n",
        "Compare the obtained MSEs with those in (30). Which method produces lower MSE for test dataset?  Which method produces lower MSE for training dataset? Do you think converting a regression problem to a classification problem is a resonable approch in general? [1 mark]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cOS_kXlgl_DJ",
      "metadata": {
        "id": "cOS_kXlgl_DJ"
      },
      "outputs": [],
      "source": [
        "#Answer to (32)\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YsRRq6C_z2I2",
      "metadata": {
        "id": "YsRRq6C_z2I2"
      },
      "source": [
        "Continued answer to (32)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yRG_h201ozzo",
      "metadata": {
        "id": "yRG_h201ozzo"
      },
      "source": [
        "(33) Convert the same regression problem in (32) to a classification problem of 100 classes. Set random_state to 42, solver='sag' and max_iter=200 in LogisticRegression. Report the MSEs for both training and test datasets.  [1 mark]\n",
        "\n",
        "Compare the obtained MSEs with those of the classification method in (32).\n",
        "Is the performance get better? [1 mark]\n",
        "\n",
        "How to futher improve the peformance of the classification method? [1 mark]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tPxYXGb9pqx4",
      "metadata": {
        "id": "tPxYXGb9pqx4"
      },
      "outputs": [],
      "source": [
        "#Answer to (33)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MDtoSgwm1-WY",
      "metadata": {
        "id": "MDtoSgwm1-WY"
      },
      "source": [
        "Continued answer to (33)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb44b820",
      "metadata": {
        "id": "cb44b820"
      },
      "source": [
        "________________\n",
        "\n",
        "# Part D – Dimensionality reduction [9 marks]\n",
        "\n",
        "Consider a scenario where you are working with a high-dimensional dataset derived from an ecological study to classify the health status of tree species based on traits such as leaf size, trunk diameter, and soil nutrient levels. The data is expected to have both linear and non-linear relationships, and you aim to reduce the dimensionality for visualization to identify potential clusters (e.g., healthy vs. diseased trees) and preprocessing for a downstream classification task."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d00a1fa",
      "metadata": {
        "id": "1d00a1fa"
      },
      "source": [
        "(34)\tDiscuss the advantages and disadvantages of using PCA, t-SNE, and UMAP for the visualization purpose, considering factors such as the preservation of local and global structures, computational efficiency, and the potential introduction of artifacts. [3 marks]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "858df0ee",
      "metadata": {
        "id": "858df0ee"
      },
      "source": [
        "Answer to (34)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "113f101a",
      "metadata": {
        "id": "113f101a"
      },
      "source": [
        "(35)\tExplain how the choice between these dimensionality reduction techniques might change when, after visualising, you want to do the preprocessing for the machine learning task. [3 marks]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99e84261",
      "metadata": {
        "id": "99e84261"
      },
      "source": [
        "Answer to (35)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18ac8f74",
      "metadata": {
        "id": "18ac8f74"
      },
      "source": [
        "(36).\tDiscuss the role of interpretability and stability in the choice of dimensionality reduction technique for both tasks. How might the stochastic nature of t-SNE and UMAP influence the reproducibility of your analyses, and how can PCA's linear assumptions limit its usefulness in capturing complex relationships in the data? [3 marks]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19df64f3",
      "metadata": {
        "id": "19df64f3"
      },
      "source": [
        "Answer to (36)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e7f2f08",
      "metadata": {
        "id": "7e7f2f08"
      },
      "source": [
        "________________\n",
        "\n",
        "# Part E – Applications of Machine Learning [17 marks]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3155c82f",
      "metadata": {
        "id": "3155c82f"
      },
      "source": [
        "(37).\tIn the context of classifying MNIST digits 7 and 8, explain why a classifier might struggle to distinguish between these digits even with high overall accuracy. Suggest two evaluation metrics that would better reveal this issue, and justify their use. [3 marks]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20c2e59c",
      "metadata": {
        "id": "20c2e59c"
      },
      "source": [
        "Answer to (37)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6b1e46a",
      "metadata": {
        "id": "c6b1e46a"
      },
      "source": [
        "(38). Given a classification task and a dataset, sometimes it’s impossible to make a classifier with 100% precision and 100% recall simultaneously. Explain why. [3 marks]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43f07d4e",
      "metadata": {
        "id": "43f07d4e"
      },
      "source": [
        "Answer to (38)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22370410",
      "metadata": {
        "id": "22370410"
      },
      "source": [
        "(39)In a recommendation system for online shopping, a machine learning model achieves high precision but struggles with low recall when recommending products to users. Explain the implications of this trade-off for the user experience, and suggest a way to improve recall without significantly sacrificing precision. [4 marks]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "157ec32b",
      "metadata": {
        "id": "157ec32b"
      },
      "source": [
        "Answer to (39)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5259805a",
      "metadata": {
        "id": "5259805a"
      },
      "source": [
        "(40)In the context of classifying MNIST digits 9 and 0 for a postal code recognition system, discuss how overfitting might occur if the model is trained on a small, clean dataset. Propose a method to detect overfitting, and suggest a way to mitigate it. [4 marks]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb71803d",
      "metadata": {
        "id": "cb71803d"
      },
      "source": [
        "Answer to (40)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a40ee58",
      "metadata": {
        "id": "0a40ee58"
      },
      "source": [
        "(41) Give an example of a machine learning algorithm that might have low error in its training and testing datasets, but that still would have a fundamental flaw in its application that is not captured by the error metric. Explain why that is the case, and suggest a way to address that. [3 marks]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7674d7b",
      "metadata": {
        "id": "e7674d7b"
      },
      "source": [
        "Answer to (41)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ba856c6",
      "metadata": {
        "id": "7ba856c6"
      },
      "source": [
        "_________________"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "cb44b820",
        "7e7f2f08"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "jupyter_notebook",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
